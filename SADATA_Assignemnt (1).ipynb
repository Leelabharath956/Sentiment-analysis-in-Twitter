{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.pipeline import Pipeline\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import re\n",
        "\n",
        "def parse_line(line):\n",
        "    parts = line.strip().split('\\t')\n",
        "    if len(parts) == 3:\n",
        "        id_, sentiment, text = parts\n",
        "        return {'id': id_, 'sentiment': sentiment, 'text': text.strip('\"')}\n",
        "    return None\n",
        "\n",
        "def load_data(file_path):\n",
        "    data = []\n",
        "    dropped_lines = 0\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        for i, line in enumerate(file, 1):\n",
        "            parsed = parse_line(line)\n",
        "            if parsed:\n",
        "                data.append(parsed)\n",
        "            else:\n",
        "                dropped_lines += 1\n",
        "                if dropped_lines <= 5:  # Print only the first 5 dropped lines\n",
        "                    print(f\"Line {i} didn't match the expected format: {line[:50]}...\")\n",
        "\n",
        "    print(f\"Total dropped lines: {dropped_lines}\")\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "# Load the data\n",
        "file_path = '/content/SADATA.txt'\n",
        "data = load_data(file_path)\n",
        "\n",
        "# Data exploration\n",
        "print(data.head())\n",
        "print(f\"\\nLoaded {len(data)} rows\")\n",
        "print(data['sentiment'].value_counts())\n",
        "\n",
        "# Visualize sentiment distribution\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "data['sentiment'].value_counts().plot(kind='bar')\n",
        "plt.title('Sentiment Distribution')\n",
        "plt.savefig('sentiment_distribution.png')\n",
        "plt.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6YSXnaqCQ_vq",
        "outputId": "d4d08cc0-924f-4464-b9cc-7b44a63ffb6f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Line 2719 didn't match the expected format: 626437371999977472\tneutral\t...Yakub may well deser...\n",
            "Line 4143 didn't match the expected format: 629712146016935936\tneutral\tTesting Motorola's Moto...\n",
            "Line 8479 didn't match the expected format: 636047266248265728\tnegative\t\"Scott Walker, who thi...\n",
            "Line 8516 didn't match the expected format: 636112894086782976\tneutral\t@lindaikeji: Super Eagl...\n",
            "Line 10201 didn't match the expected format: 637879757124669440\tneutral\t@Roman_Empire_76:   BRE...\n",
            "Total dropped lines: 11\n",
            "                   id sentiment  \\\n",
            "0  619950566786113536   neutral   \n",
            "1  619969366986235905   neutral   \n",
            "2  619971047195045888  negative   \n",
            "3  619974445185302528   neutral   \n",
            "4  619987808317407232  positive   \n",
            "\n",
            "                                                text  \n",
            "0  Picturehouse's, Pink Floyd's, 'Roger Waters: T...  \n",
            "1  Order Go Set a Watchman in store or through ou...  \n",
            "2  If these runway renovations at the airport pre...  \n",
            "3  If you could ask an onstage interview question...  \n",
            "4  A portion of book sales from our Harper Lee/Go...  \n",
            "\n",
            "Loaded 20622 rows\n",
            "sentiment\n",
            "neutral     10334\n",
            "positive     7059\n",
            "negative     3229\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data\n",
        "file_path = '/content/SADATA.txt'\n",
        "data = load_data(file_path)\n",
        "\n",
        "print(data.head())\n",
        "print(f\"\\nLoaded {len(data)} rows\")\n",
        "print(data['sentiment'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0Jp3rzZRzTd",
        "outputId": "e34941b3-939d-41f8-fc60-f2ad7027012b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Line 2719 didn't match the expected format: 626437371999977472\tneutral\t...Yakub may well deser...\n",
            "Line 4143 didn't match the expected format: 629712146016935936\tneutral\tTesting Motorola's Moto...\n",
            "Line 8479 didn't match the expected format: 636047266248265728\tnegative\t\"Scott Walker, who thi...\n",
            "Line 8516 didn't match the expected format: 636112894086782976\tneutral\t@lindaikeji: Super Eagl...\n",
            "Line 10201 didn't match the expected format: 637879757124669440\tneutral\t@Roman_Empire_76:   BRE...\n",
            "Total dropped lines: 11\n",
            "                   id sentiment  \\\n",
            "0  619950566786113536   neutral   \n",
            "1  619969366986235905   neutral   \n",
            "2  619971047195045888  negative   \n",
            "3  619974445185302528   neutral   \n",
            "4  619987808317407232  positive   \n",
            "\n",
            "                                                text  \n",
            "0  Picturehouse's, Pink Floyd's, 'Roger Waters: T...  \n",
            "1  Order Go Set a Watchman in store or through ou...  \n",
            "2  If these runway renovations at the airport pre...  \n",
            "3  If you could ask an onstage interview question...  \n",
            "4  A portion of book sales from our Harper Lee/Go...  \n",
            "\n",
            "Loaded 20622 rows\n",
            "sentiment\n",
            "neutral     10334\n",
            "positive     7059\n",
            "negative     3229\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Text preprocessing\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words('english'))"
      ],
      "metadata": {
        "id": "VvDLReTIS0Df"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    tokens = word_tokenize(text)\n",
        "    tokens = [lemmatizer.lemmatize(token) for token in tokens if token not in stop_words]\n",
        "    return ' '.join(tokens)"
      ],
      "metadata": {
        "id": "0puZDOQBS4Bp"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download necessary NLTK data\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gL6EcULyT4xI",
        "outputId": "b571dd46-a0de-413b-a650-ee65e5dc6fbe"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['processed_text'] = data['text'].apply(preprocess_text)"
      ],
      "metadata": {
        "id": "X6aQxfD6TOZd"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['processed_text'], data['sentiment'], test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "H7jjW2ReTRS8"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define models\n",
        "models = {\n",
        "    'SVM': LinearSVC(),\n",
        "    'Naive Bayes': MultinomialNB(),\n",
        "    'Random Forest': RandomForestClassifier()\n",
        "}"
      ],
      "metadata": {
        "id": "rjlwIpU4UPfG"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and evaluate models\n",
        "results = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    pipeline = Pipeline([\n",
        "        ('tfidf', TfidfVectorizer(max_features=5000)),\n",
        "        ('classifier', model)\n",
        "    ])\n",
        "\n",
        "    pipeline.fit(X_train, y_train)\n",
        "    y_pred = pipeline.predict(X_test)\n",
        "\n",
        "    print(f\"\\n{name} Classification Report:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    results[name] = pipeline\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vR827pcUfSH",
        "outputId": "25d3266a-5e4b-4837-8983-1909bbb47ae6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "SVM Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.56      0.40      0.47       619\n",
            "     neutral       0.66      0.74      0.70      2090\n",
            "    positive       0.66      0.62      0.64      1416\n",
            "\n",
            "    accuracy                           0.65      4125\n",
            "   macro avg       0.63      0.59      0.60      4125\n",
            "weighted avg       0.65      0.65      0.65      4125\n",
            "\n",
            "\n",
            "Naive Bayes Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.63      0.16      0.26       619\n",
            "     neutral       0.62      0.83      0.71      2090\n",
            "    positive       0.67      0.55      0.60      1416\n",
            "\n",
            "    accuracy                           0.63      4125\n",
            "   macro avg       0.64      0.51      0.52      4125\n",
            "weighted avg       0.64      0.63      0.60      4125\n",
            "\n",
            "\n",
            "Random Forest Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.66      0.25      0.36       619\n",
            "     neutral       0.63      0.83      0.72      2090\n",
            "    positive       0.68      0.55      0.61      1416\n",
            "\n",
            "    accuracy                           0.65      4125\n",
            "   macro avg       0.66      0.54      0.56      4125\n",
            "weighted avg       0.65      0.65      0.63      4125\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize results\n",
        "model_names = list(results.keys())\n",
        "accuracies = [classification_report(y_test, model.predict(X_test), output_dict=True)['accuracy'] for model in results.values()]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=model_names, y=accuracies)\n",
        "plt.title('Model Accuracies')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.savefig('model_accuracies.png')\n",
        "plt.close()"
      ],
      "metadata": {
        "id": "gslLo-V-UlL0"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select the best model (highest accuracy)\n",
        "best_model_name = model_names[np.argmax(accuracies)]\n",
        "best_model = results[best_model_name]\n",
        "\n",
        "print(f\"\\nBest Model: {best_model_name}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dS5_aL2PUv5F",
        "outputId": "8e03972b-4846-4963-9f18-fd9bbf79c430"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best Model: SVM\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion Matrix for the best model\n",
        "y_pred = best_model.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title(f'Confusion Matrix - {best_model_name}')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.savefig('confusion_matrix.png')\n",
        "plt.close()"
      ],
      "metadata": {
        "id": "-SCvU3cbUz7D"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Feature importance (if applicable)\n",
        "if best_model_name in ['SVM', 'Random Forest']:\n",
        "    tfidf_vectorizer = best_model.named_steps['tfidf']\n",
        "    classifier = best_model.named_steps['classifier']\n",
        "\n",
        "    if best_model_name == 'SVM':\n",
        "        feature_importance = abs(classifier.coef_[0])\n",
        "    else:  # Random Forest\n",
        "        feature_importance = classifier.feature_importances_\n",
        "\n",
        "    feature_names = tfidf_vectorizer.get_feature_names_out()\n",
        "\n",
        "    # Get top 20 features\n",
        "    top_features = sorted(zip(feature_names, feature_importance), key=lambda x: x[1], reverse=True)[:20]\n",
        "\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    sns.barplot(x=[f[1] for f in top_features], y=[f[0] for f in top_features])\n",
        "    plt.title(f'Top 20 Important Features - {best_model_name}')\n",
        "    plt.xlabel('Importance')\n",
        "    plt.ylabel('Feature')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('feature_importance.png')\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "kgraZ006U6Df"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the best model\n",
        "import joblib\n",
        "joblib.dump(best_model, 'best_sentiment_model.joblib')\n",
        "\n",
        "print(\"\\nBest model saved as 'best_sentiment_model.joblib'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UsBJ01G0VmsB",
        "outputId": "b231f01b-cc9c-472d-d36b-5f04b92882c0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best model saved as 'best_sentiment_model.joblib'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample prediction\n",
        "sample_text = \"This movie was amazing! I loved every minute of it.\"\n",
        "processed_sample = preprocess_text(sample_text)\n",
        "prediction = best_model.predict([processed_sample])\n",
        "print(f\"\\nSample text: {sample_text}\")\n",
        "print(f\"Predicted sentiment: {prediction[0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JL0wenz2VrCf",
        "outputId": "8f67a788-d8d8-4cfe-e66f-007b75368887"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sample text: This movie was amazing! I loved every minute of it.\n",
            "Predicted sentiment: positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample prediction\n",
        "sample_text = \" I loved the Movie \"\n",
        "processed_sample = preprocess_text(sample_text)\n",
        "prediction = best_model.predict([processed_sample])\n",
        "print(f\"\\nSample text: {sample_text}\")\n",
        "print(f\"Predicted sentiment: {prediction[0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "spULv3IeV0yK",
        "outputId": "5896e9c9-f877-49cc-d47d-3c4cd1be076c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sample text:  I loved the Movie \n",
            "Predicted sentiment: positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u57MbqERWAuR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}